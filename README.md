# bag-of-visual-words

* 第一步
> 读取图片，然后将图片转裁剪成统一大小（136*3，76*3），之后就RGB图转换成灰度图。然后对得到的图像去SITF特征，得到N个128位的特征值。
* 第二步
> 用K-MEANS（我将k设置为256）对刚刚提取的sift特征聚类，反复计算知道聚类的结果几乎不再变化，将对象分为256个簇，簇内部相似度高，簇之间相似度低。聚类中心有k个（在BOW模型中聚类中心我们称它们为视觉词），码本的长度也就为k，计算每一幅图像的每一个SIFT特征到这k个视觉词的距离，并将其映射到距离最近的视觉词中（即将该视觉词的对应词频+1）。完成这一步后，每一幅图像就变成了一个与视觉词序列相对应的词频矢量。
* 第三步
> 计算每种类型图和训练码本之间的距离（我们使用的是余弦距离），最后将结果倒排索引。
* 第四步
> 测试，将测试图片读入，然后和之前的码本计算余弦距离，然后进行索引，将相似度从高到低排列，计算召回率（此时找回的图片/总该类的图片）和准确率（我召回图片中正确的图片/我召回的图片）。
> 结果如下图。召回率到第六张时已经100%，准确率前六张100%，之后到前十张评价准确率时为88.7%。
